package rag

import (
	"context"

	"github.com/openai/openai-go/v3"
	"github.com/snipwise/nova/nova-sdk/agents"
	"github.com/snipwise/nova/nova-sdk/models"
	"github.com/snipwise/nova/nova-sdk/toolbox/conversion"
	"github.com/snipwise/nova/nova-sdk/toolbox/logger"

	"github.com/snipwise/nova/nova-sdk/agents/rag/stores"
)

type BaseAgent struct {
	ctx             context.Context
	config          agents.Config
	EmbeddingParams openai.EmbeddingNewParams
	openaiClient    openai.Client
	log             logger.Logger

	store stores.VectorStore

	lastRequestJSON  string
	lastResponseJSON string
}

type AgentOption func(*BaseAgent)

// NewBaseAgent creates a new RAG agent with OpenAI SDK integration
func NewBaseAgent(
	ctx context.Context,
	agentConfig agents.Config,
	modelConfig openai.EmbeddingNewParams,
	options ...AgentOption,
) (ragAgent *BaseAgent, err error) {

	client, log, err := agents.InitializeConnection(ctx, agentConfig, models.Config{
		Name: modelConfig.Model,
	})

	if err != nil {
		return nil, err
	}

	ragAgent = &BaseAgent{
		ctx:             ctx,
		config:          agentConfig,
		EmbeddingParams: modelConfig,
		openaiClient:    client,
		log:             log,

		store: &stores.MemoryVectorStore{
			Records: make(map[string]stores.VectorRecord),
		},
	}

	// Apply options (which may override the default store)
	for _, opt := range options {
		opt(ragAgent)
	}

	return ragAgent, nil
}

// GenerateEmbeddingVector creates a vector embedding for the given text content using the agent's embedding model
func (agent *BaseAgent) GenerateEmbeddingVector(content string) (embeddingVector []float64, err error) {
	// Create embedding parameters using the agent's embedding parameters

	agent.EmbeddingParams.Input = openai.EmbeddingNewParamsInputUnion{
		OfString: openai.String(content),
	}

	agent.SaveLastEmbeddingRequest()

	// Use the client to create embeddings
	embeddingResponse, err := agent.openaiClient.Embeddings.New(agent.ctx, agent.EmbeddingParams)
	if err != nil {
		return nil, err
	}

	agent.SaveLastEmbeddingResponse(embeddingResponse)

	return embeddingResponse.Data[0].Embedding, nil
}

// Embedding vector dimension: the size of the produced vector (e.g., 384, 768, 1024, 3072 dimensions).
// GetEmbeddingDimension returns the dimension of the embedding vectors generated by the agent's model
func (agent *BaseAgent) GetEmbeddingDimension() int {
	vector, err := agent.GenerateEmbeddingVector("hello")
	if err != nil {
		return 0
	}
	return len(vector)
}

// GenerateThenSaveEmbeddingVector creates a vector embedding for the given text content
func (agent *BaseAgent) GenerateThenSaveEmbeddingVector(content string) (err error) {
	embeddingVector, err := agent.GenerateEmbeddingVector(content)
	if err != nil {
		return err
	}

	_, errSave := agent.store.Save(stores.VectorRecord{
		Prompt:    content,
		Embedding: embeddingVector,
	})

	if errSave != nil {
		return errSave
	}

	return nil
}

// SearchSimilarities searches the vector store for similar records based on the embedding of the provided content
// and returns the top results up to the specified limit
// Parameters:
//   - content: the text content to generate an embedding for searching.
//   - limit: the minimum cosine distance similarity threshold. 1.0 means exact match, 0.0 means no similarity.
func (agent *BaseAgent) SearchSimilarities(content string, limit float64) (results []stores.VectorRecord, err error) {
	embeddingVector, err := agent.GenerateEmbeddingVector(content)
	if err != nil {
		return nil, err
	}

	vectorRecord := stores.VectorRecord{
		Prompt:    content,
		Embedding: embeddingVector,
	}

	results, err = agent.store.SearchSimilarities(vectorRecord, limit)
	if err != nil {
		return nil, err
	}

	return results, nil
}

// SearchTopNSimilarities searches the vector store for similar records based on the embedding of the provided content
// and returns the top N results above the specified similarity limit
// Parameters:
//   - content: the text content to generate an embedding for searching.
//   - limit: the minimum cosine distance similarity threshold. 1.0 means exact match, 0.0 means no similarity.
//   - n: the maximum number of top similar records to return.
func (agent *BaseAgent) SearchTopNSimilarities(content string, limit float64, n int) (results []stores.VectorRecord, err error) {
	embeddingVector, err := agent.GenerateEmbeddingVector(content)
	if err != nil {
		return nil, err
	}

	vectorRecord := stores.VectorRecord{
		Prompt:    content,
		Embedding: embeddingVector,
	}

	results, err = agent.store.SearchTopNSimilarities(vectorRecord, limit, n)
	if err != nil {
		return nil, err
	}

	return results, nil
}

// === Config Getters and Setters ===

// GetConfig returns the agent configuration
func (agent *BaseAgent) GetConfig() agents.Config {
	return agent.config
}

// SetConfig updates the agent configuration
func (agent *BaseAgent) SetConfig(config agents.Config) {
	agent.config = config
}

// SaveLastEmbeddingRequest saves the last embedding request JSON for logging/debugging purposes
func (agent *BaseAgent) SaveLastEmbeddingRequest() error {

	bparam, err := agent.EmbeddingParams.MarshalJSON()
	if err != nil {
		agent.log.Error("Error saving last embedding request: %v", err)
		return err
	}
	agent.lastRequestJSON = string(bparam)
	agent.log.Debug("üì° Request Sent:\n%s", agent.lastRequestJSON)

	return nil
}

func (agent *BaseAgent) SaveLastEmbeddingResponse(embeddingResponse *openai.CreateEmbeddingResponse) error {
	//Store last request and response JSON for telemetry or debugging
	agent.lastResponseJSON = embeddingResponse.RawJSON()
	agent.log.Debug("üìù Response Received:\n%s", agent.lastResponseJSON)
	return nil
}

func (agent *BaseAgent) GetLastRequestRawJSON() string {
	return agent.lastRequestJSON
}
func (agent *BaseAgent) GetLastResponseRawJSON() string {
	return agent.lastResponseJSON
}

func (agent *BaseAgent) GetLastRequestSON() (string, error) {
	return conversion.PrettyPrint(agent.lastRequestJSON)
}

func (agent *BaseAgent) GetLastResponseJSON() (string, error) {
	return conversion.PrettyPrint(agent.lastResponseJSON)
}

// GetContext returns the agent's context
func (agent *BaseAgent) GetContext() context.Context {
	return agent.ctx
}

// SetContext updates the agent's context
func (agent *BaseAgent) SetContext(ctx context.Context) {
	agent.ctx = ctx
}

// === Store Configuration Options ===

// WithInMemoryStore configures the agent to use in-memory vector storage
// This is the default behavior, so this option is only needed if you want to be explicit
func WithInMemoryStore() AgentOption {
	return func(agent *BaseAgent) {
		agent.store = &stores.MemoryVectorStore{
			Records: make(map[string]stores.VectorRecord),
		}
	}
}

// WithRedisStore configures the agent to use Redis as the vector storage backend
// Parameters:
//   - config: Redis connection configuration (address, password, DB, index name)
//   - dimension: the dimension of embedding vectors (must match your embedding model)
//
// Example:
//
//	ragAgent, err := rag.NewBaseAgent(
//	    ctx,
//	    agents.Config{EngineURL: "http://localhost:12434/engines/llama.cpp/v1"},
//	    openai.EmbeddingNewParams{Model: "ai/mxbai-embed-large"},
//	    rag.WithRedisStore(stores.RedisConfig{
//	        Address:   "localhost:6379",
//	        Password:  "",
//	        DB:        0,
//	        IndexName: "my_rag_index",
//	    }, 1024),
//	)
func WithRedisStore(config stores.RedisConfig, dimension int) AgentOption {
	return func(agent *BaseAgent) {
		redisStore, err := stores.NewRedisVectorStore(agent.ctx, config, dimension)
		if err != nil {
			agent.log.Error("Failed to create Redis vector store: %v", err)
			// Fall back to in-memory store
			agent.store = &stores.MemoryVectorStore{
				Records: make(map[string]stores.VectorRecord),
			}
			return
		}
		agent.store = redisStore
	}
}
